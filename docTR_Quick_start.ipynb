{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOb64_drQ8HZ"
      },
      "source": [
        "Looking for some examples on how to use docTR for OCR-related tasks? You've come to the right place ğŸ˜€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eiwDT8qIh4X"
      },
      "source": [
        "# Installation\n",
        "\n",
        "Install all the dependencies to make the most out of docTR. The project provides two main [installation](https://mindee.github.io/doctr/latest/installing.html) streams: one for stable release, and developer mode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh8uHvOVIvFW"
      },
      "source": [
        "## Latest stable release\n",
        "\n",
        "This will install the last stable release that was published by our teams on pypi. It is expected to provide a clean and non-buggy experience for all users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "43tpfKq1IxQg",
        "outputId": "025eb621-67a1-403d-dac3-a04f9da848d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-doctr[torch]\n",
            "  Downloading python_doctr-0.6.0-py3-none-any.whl (239 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/239.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m239.3/239.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata (from python-doctr[torch])\n",
            "  Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (1.22.4)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (1.10.1)\n",
            "Requirement already satisfied: h5py<4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (3.8.0)\n",
            "Requirement already satisfied: opencv-python<5.0.0,>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (4.7.0.72)\n",
            "Collecting pypdfium2<4.0.0,>=3.0.0 (from python-doctr[torch])\n",
            "  Downloading pypdfium2-3.21.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyclipper<2.0.0,>=1.2.0 (from python-doctr[torch])\n",
            "  Downloading pyclipper-1.3.0.post4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (813 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m813.9/813.9 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shapely<2.0.0,>=1.6.0 (from python-doctr[torch])\n",
            "  Downloading Shapely-1.8.5.post1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect<2.0.0,>=1.0.9 (from python-doctr[torch])\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (3.7.1)\n",
            "Collecting weasyprint>=55.0 (from python-doctr[torch])\n",
            "  Downloading weasyprint-59.0-py3-none-any.whl (267 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.6/267.6 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (8.4.0)\n",
            "Requirement already satisfied: defusedxml>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (0.7.1)\n",
            "Collecting mplcursors>=0.3 (from python-doctr[torch])\n",
            "  Downloading mplcursors-0.5.2.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.0/89.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidecode>=1.0.0 (from python-doctr[torch])\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (4.65.0)\n",
            "Collecting rapidfuzz>=1.6.0 (from python-doctr[torch])\n",
            "  Downloading rapidfuzz-3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from python-doctr[torch])\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->python-doctr[torch]) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->python-doctr[torch]) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->python-doctr[torch]) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->python-doctr[torch]) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->python-doctr[torch]) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->python-doctr[torch]) (23.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect<2.0.0,>=1.0.9->python-doctr[torch]) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->python-doctr[torch]) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->python-doctr[torch]) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->python-doctr[torch]) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->python-doctr[torch]) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->python-doctr[torch]) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->python-doctr[torch]) (2.8.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->python-doctr[torch]) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->python-doctr[torch]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->python-doctr[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->python-doctr[torch]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->python-doctr[torch]) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->python-doctr[torch]) (16.0.6)\n",
            "Collecting pydyf>=0.6.0 (from weasyprint>=55.0->python-doctr[torch])\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# TensorFlow\n",
        "# !pip install python-doctr[tf]\n",
        "# PyTorch\n",
        "!pip install python-doctr[torch]\n",
        "# Restart runtime\n",
        "exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUbhZiRiIxbN"
      },
      "source": [
        "## From source\n",
        "\n",
        "Before being staged for a stable release, we constantly iterate on the community feedback to improve the library. Bug fixes and performance improvements are regularly pushed to the project Git repository. Using this installation method, you will access all the latest features that have not yet made their way to a pypi release!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJZgLM_CIzKf"
      },
      "outputs": [],
      "source": [
        "# Colab related installations to install pyproject.toml projects correctly\n",
        "!sudo apt install libcairo2-dev pkg-config\n",
        "!pip3 install pycairo\n",
        "# Install the most up-to-date version from GitHub\n",
        "# TensorFlow\n",
        "# !pip install python-doctr[tf]@git+https://github.com/mindee/doctr.git\n",
        "# PyTorch\n",
        "!pip3 install python-doctr[torch]@git+https://github.com/mindee/doctr.git\n",
        "# Restart runtime\n",
        "exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvJ3PzAQI0zK"
      },
      "source": [
        "Now go to  `Runtime/Restart runtime` for your changes to take effect!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2mgRuCaJY4F"
      },
      "source": [
        "# Basic usage\n",
        "\n",
        "We're going to review the main features of docTR ğŸ\n",
        "And for you to have a proper overview of its capabilities, we will need some free fonts for a proper output visualization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Qhrp88TPDZi"
      },
      "outputs": [],
      "source": [
        "# Install some free fonts for result rendering\n",
        "!sudo apt-get install fonts-freefont-ttf -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe7KuocKSWX9"
      },
      "source": [
        "Let's take care of all the imports directly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSoeo0hRJbnU"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "\n",
        "# Let's pick the desired backend\n",
        "# os.environ['USE_TF'] = '1'\n",
        "os.environ['USE_TORCH'] = '1'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from doctr.io import DocumentFile\n",
        "from doctr.models import ocr_predictor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wwEmHqZSaLF"
      },
      "source": [
        "For the next steps, we will need a proper PDF document that will be used to showcase the library features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIBwFsVuJocy"
      },
      "outputs": [],
      "source": [
        "# Download a sample\n",
        "!wget https://eforms.com/download/2019/01/Cash-Payment-Receipt-Template.pdf\n",
        "# Read the file\n",
        "doc = DocumentFile.from_pdf(\"Cash-Payment-Receipt-Template.pdf\")\n",
        "print(f\"Number of pages: {len(doc)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM6PPiWpSmb0"
      },
      "source": [
        "docTR is, under the hood, running Deep Learning models to perform the different tasks it supports. Those models were built and trained with very popular frameworks for maximum compatibility (you will be pleased to know that you can switch from [PyTorch](https://pytorch.org/) to [TensorFlow](https://www.tensorflow.org/) without noticing any difference for you). By default, our high-level API sets the best default values so that you get high performing models without having to know anything about it. All of this is wrapper in a `Predictor` object, which will take care of pre-processing, model inference and post-processing for you âš¡\n",
        "\n",
        "Let's instantiate one!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAoUcVQbKIfT"
      },
      "outputs": [],
      "source": [
        "# Instantiate a pretrained model\n",
        "predictor = ocr_predictor(pretrained=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKKYSs0ET0XQ"
      },
      "source": [
        "By default, PyTorch model provides a nice visual description of a model, which is handy when it comes to debugging or knowing what you just created. We also added a similar feature for TensorFlow backend so that you don't miss on this nice assistance.\n",
        "\n",
        "Let's dive into this model ğŸ•µ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urR0KyUYOT-B"
      },
      "outputs": [],
      "source": [
        "# Display the architecture\n",
        "print(predictor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlrtkNzTURAo"
      },
      "source": [
        "Here we are inspecting the most complex (and high-level) object of docTR API: an OCR predictor. Since docTR achieves Optical Character Recognition by first localizing textual elements (Text Detection), then extracting the corresponding text from each location (Text Recognition), the OCR Predictor wraps two sub-predictors: one for text detection, and the other for text recognition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyVfbzhUL-Rw"
      },
      "source": [
        "## Basic inference\n",
        "\n",
        "It looks quite complex, isn't it?\n",
        "Well that will not prevent you from easily get nice results. See for yourself:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLPsdCj3PWzI"
      },
      "outputs": [],
      "source": [
        "result = predictor(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFAwQaKuPYXG"
      },
      "source": [
        "## Prediction visualization\n",
        "\n",
        "If you rightfully prefer to see the results with your eyes, docTR includes a few visualization features. We will first overlay our predictions on the original document:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOcqPNnPMAE7"
      },
      "outputs": [],
      "source": [
        "result.show(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnJERph1VXgN"
      },
      "source": [
        "Looks accurate!\n",
        "But we can go further: if the extracted information is correctly structured, we should be able to recreate the page entirely. So let's do this ğŸ¨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdoSNYzROeRv"
      },
      "outputs": [],
      "source": [
        "synthetic_pages = result.synthesize()\n",
        "plt.imshow(synthetic_pages[0]); plt.axis('off'); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEabainyPeV8"
      },
      "source": [
        "## Exporting results\n",
        "\n",
        "OK, so the predictions are relevant, but how would you integrate this into your own document processing pipeline? Perhaps you're not using Python at all?\n",
        "\n",
        "Well, if you happen to be using JSON or XML exports, they are already supported ğŸ¤—"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhIolyjQOqLp"
      },
      "outputs": [],
      "source": [
        "# JSON export\n",
        "json_export = result.export()\n",
        "print(json_export)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RsuKIlYPnNf"
      },
      "outputs": [],
      "source": [
        "# XML export\n",
        "xml_output = result.export_as_xml()\n",
        "print(xml_output[0][0])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "docTR - Quick start.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}